# -*- coding: utf-8 -*-
"""XGBoost and VGG16 as feature extractor

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yK57-GV-8R9i5W546A7BgK7RMSUxvZmm

**Import libraries**
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score
from sklearn.metrics import classification_report

from keras.applications.vgg16 import VGG16

from xgboost import XGBClassifier

"""**Load the dataset and data exploratory**"""

#Load dataset
df_train = pd.read_json("/content/drive/MyDrive/train.json")
df_train.head()

print(df_train.shape)

print(df_train.info())

# MISSING VALUES:
#NOTE: we want to find "Nan" filds and replace it
df_train.inc_angle.replace({"na":np.nan}, inplace=True)
# Drop the rows that has NaN value for inc_angle
df_train.drop(df_train[df_train["inc_angle"].isnull()].index, inplace=True)

iceberg_size = df_train["is_iceberg"].value_counts(sort=1)
plt.pie(iceberg_size, autopct = "%1.1f%%")
plt.show()

def prepare_data(df):
    X_band_1 = []
    X_band_2 = []
    
    for band in df["band_1"]:
        #Convert to float32
        band_1 = np.array(band).astype(np.float32)
        #Reshaping band_1 and band_2
        band_1 = band_1.reshape(75,75)
        X_band_1.append(band_1)
        
    for band in df["band_2"]:
         #Convert to float32
        band_2 = np.array(band).astype(np.float32)
        #Reshaping band_1 and band_2
        band_2 = band_2.reshape(75,75)
        X_band_2.append(band_2)
        
    #Convert list to numpy array
    X_band_1 = np.array(X_band_1)
    X_band_2 = np.array(X_band_2)
    
    # Rescale
    X_band_1 = (X_band_1 - X_band_1.mean()) / (X_band_1.max() - X_band_1.min())
    X_band_2 = (X_band_2 - X_band_2.mean()) / (X_band_2.max() - X_band_2.min())
    
    #Concatenate band_1 and band_2 to create X for training (or test)
    X = np.concatenate([X_band_1[:, :, :, np.newaxis], 
                        X_band_2[:, :, :, np.newaxis],((X_band_1+X_band_2)/2)[:, :, :, np.newaxis]], 
                        axis=-1)
    
    Y = np.array(df["is_iceberg"])
    
    return X, Y

# Load X and Y
X, Y = prepare_data(df_train)

print("X shape is:{}".format(X.shape))
print("Y shape is:{}".format(Y.shape))

""" **Transfer learning using VGG16**"""

SIZE = 75

# Split data to train and test
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)

print("X_train shape is:{}".format(X_train.shape))
print("Y_train shape is:{}".format(Y_train.shape))
print("X_test shape is:{}".format(X_test.shape))
print("Y_test shape is:{}".format(Y_test.shape))

# Normalize and reshape
X_train = X_train.astype("float32")
X_test = X_test.astype("float32")
X_train = X_train / 255
X_test = X_test / 255

# Now load vgg16 model without fully connected layer
vgg_model = VGG16(weights="imagenet", include_top=False, input_shape=(SIZE, SIZE, 3))
vgg_model.summary()

# Make loaded layers non-trainable
# Trainable layers will be equal to 0
for layer in vgg_model.layers:
    layer.trainable = False
    
vgg_model.summary()

# Now we want to use feature extarctor of vgg model for XGBoost model
feature_vgg16 = vgg_model.predict(X_train)
features = feature_vgg16.reshape(feature_vgg16.shape[0], -1)

# exactly the same process for testing data
feature_for_Xtest = vgg_model.predict(X_test)
X_test_features = feature_for_Xtest.reshape(feature_for_Xtest.shape[0], -1)

# features extracted from vgg model is going to be X for XGbosst
X_training = features

"""**XGBoost Image Classification**"""

model = XGBClassifier()
# For sklearn model we do not need one-hot encoding for Y
model.fit(X_training, Y_train)

# Here, we predict XGB model using X_test_features
prediction = model.predict(X_test_features)

"""**Model Accuracy**"""

accuracy = accuracy_score(Y_test, prediction)
print("Accuracy = {}".format(accuracy))

# Confusion matrix
cm = confusion_matrix(Y_test, prediction)
sns.heatmap(cm, annot=True)

print(classification_report(Y_test, prediction))

#Check results on a few select images
num = np.random.randint(0, X_test.shape[0])
img = X_test[num]
plt.imshow(img[:,:,0])
#Expand dimension so the input is (num images, x, y, c)
input_img = np.expand_dims(img, axis=0) 
img_feature = vgg_model.predict(input_img)
img_features = img_feature.reshape(img_feature.shape[0], -1)
y_pred = model.predict(img_features)[0] 
print("The prediction for this image is: ", y_pred)
print("The actual label for this image is: ", Y_test[num])

#Check results on a few select images
num = np.random.randint(0, X_test.shape[0])
img = X_test[num]
plt.imshow(img[:,:,0])
#Expand dimension so the input is (num images, x, y, c)
input_img = np.expand_dims(img, axis=0) 
img_feature = vgg_model.predict(input_img)
img_features = img_feature.reshape(img_feature.shape[0], -1)
y_pred = model.predict(img_features)[0] 
print("The prediction for this image is: ", y_pred)
print("The actual label for this image is: ", Y_test[num])