# -*- coding: utf-8 -*-
"""Resnet50

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yK57-GV-8R9i5W546A7BgK7RMSUxvZmm

**Import libraries**
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import pickle

from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.decomposition import PCA
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score
from sklearn.metrics import classification_report

from keras.applications.resnet50 import ResNet50
from keras.utils import to_categorical
from keras.models import Model
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import Conv2D
from keras.layers import BatchNormalization
from keras.layers import Flatten
from keras.layers import Dropout
from keras.optimizers import SGD

"""**Load the dataset and data exploratory**"""

#Load dataset
df_train = pd.read_json("/content/drive/MyDrive/train.json")
df_train.head()

print(df_train.shape)

print(df_train.info())

# MISSING VALUES:
#NOTE: we want to find "Nan" filds and replace it
df_train.inc_angle.replace({"na":np.nan}, inplace=True)
# Drop the rows that has NaN value for inc_angle
df_train.drop(df_train[df_train["inc_angle"].isnull()].index, inplace=True)

iceberg_size = df_train["is_iceberg"].value_counts(sort=1)
plt.pie(iceberg_size, autopct = "%1.1f%%")
plt.show()

def prepare_data(df):
    X_band_1 = []
    X_band_2 = []
    
    for band in df["band_1"]:
        #Convert to float32
        band_1 = np.array(band).astype(np.float32)
        #Reshaping band_1 and band_2
        band_1 = band_1.reshape(75,75)
        X_band_1.append(band_1)
        
    for band in df["band_2"]:
         #Convert to float32
        band_2 = np.array(band).astype(np.float32)
        #Reshaping band_1 and band_2
        band_2 = band_2.reshape(75,75)
        X_band_2.append(band_2)
        
    #Convert list to numpy array
    X_band_1 = np.array(X_band_1)
    X_band_2 = np.array(X_band_2)
    
    # Rescale
    X_band_1 = (X_band_1 - X_band_1.mean()) / (X_band_1.max() - X_band_1.min())
    X_band_2 = (X_band_2 - X_band_2.mean()) / (X_band_2.max() - X_band_2.min())
    
    #Concatenate band_1 and band_2 to create X for training (or test)
    X = np.concatenate([X_band_1[:, :, :, np.newaxis], 
                        X_band_2[:, :, :, np.newaxis],((X_band_1+X_band_2)/2)[:, :, :, np.newaxis]], 
                        axis=-1)
    
    Y = np.array(df["is_iceberg"])
    
    return X, Y

# Load X and Y
X, Y = prepare_data(df_train)

print("X shape is:{}".format(X.shape))
print("Y shape is:{}".format(Y.shape))

"""**Transfer learning using ResNet50**"""

SIZE = 75

# Split data
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.1, random_state=42)

print("X_train shape is:{}".format(X_train.shape))
print("Y_train shape is:{}".format(Y_train.shape))
print("X_test shape is:{}".format(X_test.shape))
print("Y_test shape is:{}".format(Y_test.shape))

# Normalize and reshape
X_train = X_train.astype("float32")
X_test = X_test.astype("float32")
X_train = X_train / 255
X_test = X_test / 255

# One hot encoding
y_train_one_hot = to_categorical(Y_train)
y_test_one_hot = to_categorical(Y_test)

# Load model
resnet50_model = ResNet50(weights="imagenet", include_top=False, input_shape=(SIZE, SIZE, 3))
resnet50_model.summary()

# Make Loaded layers as non-trainable
for layer in resnet50_model.layers:
    layer.trainable = False
    
resnet50_model.summary()

# Set the flat layers
flat_layer = Flatten()(resnet50_model.layers[-1].output)
dense_layer = Dense(75, activation='relu', kernel_initializer='he_uniform')(flat_layer)
output_layer = Dense(1, activation='sigmoid')(dense_layer)

# Set a new model
newmodel = Model(inputs=resnet50_model.inputs, outputs=output_layer) 

# compile the new model
optimizer = SGD(lr=0.01, momentum=0.9)
newmodel.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])

newmodel.summary()

new_model.summary()

# Fit the model and check the accuracy
transfer_model = newmodel.fit(X_train, Y_train, batch_size=32, epochs=25, verbose=1, validation_data=(X_test, Y_test))
loss, acc = newmodel.evaluate(X_test, Y_test, verbose=1)
print('\nTesting loss: {}, acc: {}\n'.format(loss, acc))

loss = transfer_model.history['loss']
val_loss = transfer_model.history['val_loss']
epochs = range(1, len(loss) + 1)
plt.plot(epochs, loss, 'y', label='Training loss')
plt.plot(epochs, val_loss, 'r', label='Validation loss')
plt.title('Training and validation loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

acc = transfer_model.history['accuracy']
val_acc = transfer_model.history['val_accuracy']
plt.plot(epochs, acc, 'y', label='Training accuracy')
plt.plot(epochs, val_acc, 'r', label='Validation accuracy')
plt.title('Training and validation accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

# prediction the newmodel
y_pred = newmodel.predict(X_test)

# Evaluate model
test_loss, test_acc = newmodel.evaluate(X_test, Y_test, verbose=0)
print("Test Score = ", test_loss)
print("Test Accuracy = ", test_acc)